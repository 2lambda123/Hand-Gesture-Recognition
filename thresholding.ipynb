{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from utils import Utils\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "menPath = \"../Dataset_0-5/men/\"\n",
    "womenPath = \"../Dataset_0-5/Women/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img_width = 480\n",
    "start_time = time.time()\n",
    "img = cv.imread('../Dataset_0-5/men/4/4_men (1).JPG')\n",
    "h, w = img.shape[:2]\n",
    "new_height = int(h * img_width / w)\n",
    "img_size = (img_width, new_height)\n",
    "img = cv.resize(img, img_size)    # resize image\n",
    "\n",
    "# Convert the image from BGR to YCbCr\n",
    "ycbcr_image = cv.cvtColor(img, cv.COLOR_BGR2YCR_CB)\n",
    "\n",
    "# Extract Cr and Cb channels\n",
    "cr = ycbcr_image[:, :, 1]\n",
    "cb = ycbcr_image[:, :, 2]\n",
    "\n",
    "# Reshape channels into a 1D array\n",
    "cr_flat = cr.flatten().reshape(-1, 1)\n",
    "cb_flat = cb.flatten().reshape(-1, 1)\n",
    "\n",
    "# Concatenate channels into a single array\n",
    "x = np.concatenate((cr_flat, cb_flat), axis=1)\n",
    "\n",
    "# Fit Gaussian mixture model\n",
    "gmm = GaussianMixture(n_components=2)\n",
    "gmm.fit(x)\n",
    "\n",
    "# Predict probabilities of each pixel belonging to background or foreground\n",
    "probs = gmm.predict_proba(x)\n",
    "probs_bg = probs[:, 0].reshape(cr.shape)\n",
    "probs_fg = probs[:, 1].reshape(cr.shape)\n",
    "\n",
    "# Threshold probabilities to extract foreground object from background\n",
    "thresh = 0.5\n",
    "mask1 = (probs_fg > thresh).astype(np.uint8) * 255\n",
    "# Threshold probabilities to extract background object from foreground\n",
    "# mask2 = (probs_bg > thresh).astype(np.uint8) * 255\n",
    "# Apply mask to original image\n",
    "result1 = cv.bitwise_and(img, img, mask=mask1)\n",
    "result2 = cv.bitwise_and(img, img, mask=~(mask1))\n",
    "black_pixels1 = (result1 == np.array([0, 0, 0])).all(axis=2)\n",
    "black_pixels2 = (result2 == np.array([0, 0, 0])).all(axis=2)\n",
    "\n",
    "# extract the hand from the image\n",
    "out = cv.bitwise_or(result1, result2)\n",
    "end_time = time.time()\n",
    "totTime = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\CMP\\third_Year\\second_semester\\pattern Recognition\\project\\Hand-Gesture-Recognition\\thresholding.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CMP/third_Year/second_semester/pattern%20Recognition/project/Hand-Gesture-Recognition/thresholding.ipynb#W3sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m cv\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CMP/third_Year/second_semester/pattern%20Recognition/project/Hand-Gesture-Recognition/thresholding.ipynb#W3sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m cv\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mresult3\u001b[39m\u001b[39m'\u001b[39m,  cv\u001b[39m.\u001b[39mresize(result3, (\u001b[39m1024\u001b[39m, \u001b[39m512\u001b[39m)))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/CMP/third_Year/second_semester/pattern%20Recognition/project/Hand-Gesture-Recognition/thresholding.ipynb#W3sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m cv\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m0\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1, 20):\n",
    "    img = cv.imread(f'../Dataset_0-5/men/2/2_men ({i}).JPG')\n",
    "    img_width = 120\n",
    "    h, w = img.shape[:2]\n",
    "    new_height = int(h * img_width / w)\n",
    "    img_size = (img_width, new_height)\n",
    "    img = cv.resize(img, img_size)    # resize image\n",
    "\n",
    "    # Convert the image from BGR to YCbCr\n",
    "    ycbcr_image = cv.cvtColor(img, cv.COLOR_BGR2YCR_CB)\n",
    "\n",
    "    # Extract Cr and Cb channels\n",
    "    cr = ycbcr_image[:, :, 1]\n",
    "    cb = ycbcr_image[:, :, 2]\n",
    "\n",
    "    # Reshape channels into a 1D array\n",
    "    cr_flat = cr.flatten().reshape(-1, 1)\n",
    "    cb_flat = cb.flatten().reshape(-1, 1)\n",
    "\n",
    "    # Concatenate channels into a single array\n",
    "    x = np.concatenate((cr_flat, cb_flat), axis=1)\n",
    "\n",
    "    # Fit Gaussian mixture model\n",
    "    gmm = GaussianMixture(n_components=3)\n",
    "    gmm.fit(x)\n",
    "\n",
    "    # Predict probabilities of each pixel belonging to background or foreground\n",
    "    probs = gmm.predict_proba(x)\n",
    "    probs_bg = probs[:, 0].reshape(cr.shape)\n",
    "    probs_fg = probs[:, 1].reshape(cr.shape)\n",
    "    probs_sh = probs[:, 2].reshape(cr.shape)\n",
    "    # Threshold probabilities to extract foreground object from background\n",
    "    thresh = 0.5\n",
    "    mask1 = (probs_fg > thresh).astype(np.uint8) * 255\n",
    "    mask2 = (probs_bg > thresh).astype(np.uint8) * 255\n",
    "    mask3 = (probs_sh > thresh).astype(np.uint8) * 255\n",
    "    # Apply mask to original image\n",
    "    result1 = cv.bitwise_and(img, img, mask=mask1)\n",
    "    result2 = cv.bitwise_and(img, img, mask=(mask2))\n",
    "    result3 = cv.bitwise_and(img, img, mask=(mask3))\n",
    "# extract the hand from the image\n",
    "# Convert mask to grayscale and apply thresholding to extract hand from background\n",
    "# gray_mask = cv.cvtColor(mask, cv.COLOR_GRAY2BGR)\n",
    "# _, binary_mask = cv.threshold(gray_mask, 0, 255, cv.THRESH_BINARY)\n",
    "\n",
    "# # Apply binary mask to original image to extract hand from background\n",
    "# hand = cv.bitwise_and(img, img, mask=binary_mask)\n",
    "# Convert image to YCrCb color space\n",
    "# img_ycrcb1 = cv.cvtColor(result1, cv.COLOR_BGR2YCrCb)\n",
    "# img_ycrcb2 = cv.cvtColor(result2, cv.COLOR_BGR2YCrCb)\n",
    "\n",
    "# # Define range of skin color in YCrCb color space\n",
    "# lower_skin = np.array([0, 135, 85], dtype=np.uint8)\n",
    "# upper_skin = np.array([255, 180, 135], dtype=np.uint8)\n",
    "\n",
    "# # Extract skin color from image\n",
    "# mask1 = cv.inRange(img_ycrcb1, lower_skin, upper_skin)\n",
    "# mask2 = cv.inRange(img_ycrcb2, lower_skin, upper_skin)\n",
    "\n",
    "# # Apply morphological operations to remove noise from mask\n",
    "# kernel = np.ones((3, 3), np.uint8)\n",
    "# mask1 = cv.erode(mask1, kernel, iterations=1)\n",
    "# mask1 = cv.dilate(mask1, kernel, iterations=1)\n",
    "\n",
    "# mask2 = cv.erode(mask2, kernel, iterations=1)\n",
    "# mask2 = cv.dilate(mask2, kernel, iterations=1)\n",
    "\n",
    "# # Apply mask to original image to extract hand\n",
    "# result1 = cv.bitwise_and(img, img, mask=mask1)\n",
    "# result2 = cv.bitwise_and(img, img, mask=mask2)\n",
    "# resGrey1 = Utils.getMaskedHand(result1)\n",
    "# resGrey2 = Utils.getMaskedHand(result2)\n",
    "# mean1 = np.mean(resGrey1)\n",
    "# mean2 = np.mean(resGrey2)\n",
    "# print(mean1, mean2)\n",
    "# if mean1 > mean2:\n",
    "#     result = result1\n",
    "# else:\n",
    "#     result = result2\n",
    "cv.imshow('result1',  cv.resize(result1, (1024, 512)))\n",
    "cv.waitKey(0)\n",
    "cv.imshow('result2',  cv.resize(result2, (1024, 512)))\n",
    "cv.waitKey(0)\n",
    "cv.imshow('result3',  cv.resize(result3, (1024, 512)))\n",
    "cv.waitKey(0)\n",
    "# # while True:\n",
    "# class_dir = os.path.join(menPath, f\"{0}\")\n",
    "# imgPath = os.path.join(class_dir, f'{0}_men ({1}).JPG')\n",
    "# img = cv.imread(imgPath)\n",
    "# img = getThresholdedHand(img)\n",
    "# cv.imshow(\"img\", img)\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.5877845287322998\n",
      "Time:  1.8996868133544922\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\CMP\\third_Year\\second_semester\\pattern Recognition\\project\\Hand-Gesture-Recognition\\thresholding.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CMP/third_Year/second_semester/pattern%20Recognition/project/Hand-Gesture-Recognition/thresholding.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m21\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/CMP/third_Year/second_semester/pattern%20Recognition/project/Hand-Gesture-Recognition/thresholding.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     out \u001b[39m=\u001b[39m Utils\u001b[39m.\u001b[39;49mextract_hand( cv\u001b[39m.\u001b[39;49mimread(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../Dataset_0-5/men/0/0_men (\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m).JPG\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CMP/third_Year/second_semester/pattern%20Recognition/project/Hand-Gesture-Recognition/thresholding.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     cv\u001b[39m.\u001b[39mimshow(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mout\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,  cv\u001b[39m.\u001b[39mresize(out, (\u001b[39m1024\u001b[39m, \u001b[39m512\u001b[39m)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/CMP/third_Year/second_semester/pattern%20Recognition/project/Hand-Gesture-Recognition/thresholding.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     cv\u001b[39m.\u001b[39mwaitKey(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32md:\\CMP\\third_Year\\second_semester\\pattern Recognition\\project\\Hand-Gesture-Recognition\\utils.py:374\u001b[0m, in \u001b[0;36mUtils.extract_hand\u001b[1;34m(img, img_width)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39m# Fit Gaussian mixture model\u001b[39;00m\n\u001b[0;32m    373\u001b[0m gmm \u001b[39m=\u001b[39m GaussianMixture(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m--> 374\u001b[0m gmm\u001b[39m.\u001b[39mfit(x)\n\u001b[0;32m    376\u001b[0m \u001b[39m# Predict probabilities of each pixel belonging to background or foreground\u001b[39;00m\n\u001b[0;32m    377\u001b[0m probs \u001b[39m=\u001b[39m gmm\u001b[39m.\u001b[39mpredict_proba(x)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:200\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    175\u001b[0m     \u001b[39m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \n\u001b[0;32m    177\u001b[0m \u001b[39m    The method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m        The fitted mixture.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_predict(X, y)\n\u001b[0;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:253\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_verbose_msg_init_beg(init)\n\u001b[0;32m    252\u001b[0m \u001b[39mif\u001b[39;00m do_init:\n\u001b[1;32m--> 253\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize_parameters(X, random_state)\n\u001b[0;32m    255\u001b[0m lower_bound \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf \u001b[39mif\u001b[39;00m do_init \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlower_bound_\n\u001b[0;32m    257\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:160\u001b[0m, in \u001b[0;36mBaseMixture._initialize_parameters\u001b[1;34m(self, X, random_state)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    157\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnimplemented initialization method \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_params\n\u001b[0;32m    158\u001b[0m     )\n\u001b[1;32m--> 160\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(X, resp)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:713\u001b[0m, in \u001b[0;36mGaussianMixture._initialize\u001b[1;34m(self, X, resp)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39m\"\"\"Initialization of the Gaussian mixture parameters.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[39mresp : array-like of shape (n_samples, n_components)\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    711\u001b[0m n_samples, _ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m--> 713\u001b[0m weights, means, covariances \u001b[39m=\u001b[39m _estimate_gaussian_parameters(\n\u001b[0;32m    714\u001b[0m     X, resp, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreg_covar, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcovariance_type\n\u001b[0;32m    715\u001b[0m )\n\u001b[0;32m    716\u001b[0m weights \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m n_samples\n\u001b[0;32m    718\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights_ \u001b[39m=\u001b[39m weights \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights_init \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights_init\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:290\u001b[0m, in \u001b[0;36m_estimate_gaussian_parameters\u001b[1;34m(X, resp, reg_covar, covariance_type)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39m\"\"\"Estimate the Gaussian distribution parameters.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \n\u001b[0;32m    263\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m    The shape depends of the covariance_type.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    289\u001b[0m nk \u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m10\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mfinfo(resp\u001b[39m.\u001b[39mdtype)\u001b[39m.\u001b[39meps\n\u001b[1;32m--> 290\u001b[0m means \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(resp\u001b[39m.\u001b[39;49mT, X) \u001b[39m/\u001b[39m nk[:, np\u001b[39m.\u001b[39mnewaxis]\n\u001b[0;32m    291\u001b[0m covariances \u001b[39m=\u001b[39m {\n\u001b[0;32m    292\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m: _estimate_gaussian_covariances_full,\n\u001b[0;32m    293\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtied\u001b[39m\u001b[39m\"\u001b[39m: _estimate_gaussian_covariances_tied,\n\u001b[0;32m    294\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdiag\u001b[39m\u001b[39m\"\u001b[39m: _estimate_gaussian_covariances_diag,\n\u001b[0;32m    295\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mspherical\u001b[39m\u001b[39m\"\u001b[39m: _estimate_gaussian_covariances_spherical,\n\u001b[0;32m    296\u001b[0m }[covariance_type](resp, X, nk, means, reg_covar)\n\u001b[0;32m    297\u001b[0m \u001b[39mreturn\u001b[39;00m nk, means, covariances\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(1, 21):\n",
    "    out = Utils.extract_hand( cv.imread(f\"../Dataset_0-5/men/0/0_men ({i}).JPG\"))\n",
    "    cv.imshow(f\"out{i}\",  cv.resize(out, (1024, 512)))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image\n",
    "img = cv.imread('../Dataset_0-5/men/4/4_men (1).JPG')\n",
    "\n",
    "# Convert the image from BGR to YCbCr\n",
    "ycbcr_image = cv.cvtColor(img, cv.COLOR_BGR2YCR_CB)\n",
    "\n",
    "# Extract the Cb and Cr channels from the YCbCr image\n",
    "cb_channel = ycbcr_image[:, :, 1]\n",
    "cr_channel = ycbcr_image[:, :, 2]\n",
    "\n",
    "# Reshape the Cb and Cr channels into 1D arrays\n",
    "cb_channel_1d = np.reshape(cb_channel, (-1, 1))\n",
    "cr_channel_1d = np.reshape(cr_channel, (-1, 1))\n",
    "\n",
    "# Concatenate the Cb and Cr channels into a single 2D array\n",
    "cbcr_channels = np.concatenate((cb_channel_1d, cr_channel_1d), axis=1)\n",
    "\n",
    "# Fit a Gaussian mixture model to the Cb and Cr channels\n",
    "gmm = GaussianMixture(n_components=2)\n",
    "gmm.fit(cbcr_channels)\n",
    "\n",
    "# Predict the labels for each pixel in the Cb and Cr channels\n",
    "labels = gmm.predict(cbcr_channels)\n",
    "\n",
    "# Reshape the labels back into a 2D array\n",
    "labels_2d = np.reshape(labels, cb_channel.shape)\n",
    "\n",
    "# Convert the labels to uint8 data type\n",
    "labels_2d_uint8 = labels_2d.astype(np.float64)\n",
    "print(labels_2d_uint8.max())\n",
    "# Display the labels as an image\n",
    "cv.imshow('Labels',  cv.resize(labels_2d_uint8, (1024, 512)))\n",
    "cv.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load image\n",
    "img = cv.imread('../Dataset_0-5/men/2/2_men (9).JPG')\n",
    "\n",
    "# Convert image to YCrCb color space\n",
    "img_ycrcb = cv.cvtColor(img, cv.COLOR_BGR2YCrCb)\n",
    "\n",
    "# Define range of skin color in YCrCb color space\n",
    "lower_skin = np.array([0, 135, 85], dtype=np.uint8)\n",
    "upper_skin = np.array([255, 180, 135], dtype=np.uint8)\n",
    "\n",
    "# Extract skin color from image\n",
    "mask = cv.inRange(img_ycrcb, lower_skin, upper_skin)\n",
    "\n",
    "# Apply morphological operations to remove noise from mask\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "mask = cv.erode(mask, kernel, iterations=1)\n",
    "mask = cv.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "# Apply mask to original image to extract hand\n",
    "result = cv.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv.imshow('r',  cv.resize(result, (1024, 512)))\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
