{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from utils import Utils\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "menPath = \"../Dataset_0-5/men/\"\n",
    "womenPath = \"../Dataset_0-5/Women/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 10):\n",
    "    # Load the image\n",
    "    img = cv.imread(f'../Dataset_0-5/men/2/2_men ({i}).JPG')\n",
    "    start_time = time.time()\n",
    "    img_width = 120\n",
    "    h, w = img.shape[:2]\n",
    "    new_height = int(h * img_width / w)\n",
    "    img_size = (img_width, new_height)\n",
    "    img = cv.resize(img, img_size)    # resize image\n",
    "\n",
    "    # Convert the image from BGR to YCbCr\n",
    "    ycbcr_image = cv.cvtColor(img, cv.COLOR_BGR2YCR_CB)\n",
    "\n",
    "    # Extract Cr and Cb channels\n",
    "    cr = ycbcr_image[:, :, 1]\n",
    "    cb = ycbcr_image[:, :, 2]\n",
    "\n",
    "    # Reshape channels into a 1D array\n",
    "    cr_flat = cr.flatten().reshape(-1, 1)\n",
    "    cb_flat = cb.flatten().reshape(-1, 1)\n",
    "\n",
    "    # Concatenate channels into a single array\n",
    "    x = np.concatenate((cr_flat, cb_flat), axis=1)\n",
    "\n",
    "    # Fit Gaussian mixture model\n",
    "    gmm = GaussianMixture(n_components=2)\n",
    "    gmm.fit(x)\n",
    "\n",
    "    # Predict probabilities of each pixel belonging to background or foreground\n",
    "    probs = gmm.predict_proba(x)\n",
    "    probs_bg = probs[:, 0].reshape(cr.shape)\n",
    "    probs_fg = probs[:, 1].reshape(cr.shape)\n",
    "\n",
    "    # Threshold probabilities to extract foreground object from background\n",
    "    thresh = 0.5\n",
    "    mask = (probs_fg > thresh).astype(np.uint8) * 255\n",
    "\n",
    "    # Apply mask to original image\n",
    "    result1 = cv.bitwise_and(img, img, mask=mask)\n",
    "    result2 = cv.bitwise_and(img, img, mask=~(mask))\n",
    "\n",
    "    # Convert image to YCrCb color space\n",
    "    img_ycrcb1 = cv.cvtColor(result1, cv.COLOR_BGR2YCrCb)\n",
    "    img_ycrcb2 = cv.cvtColor(result2, cv.COLOR_BGR2YCrCb)\n",
    "\n",
    "    # Define range of skin color in YCrCb color space\n",
    "    lower_skin = np.array([0, 135, 85], dtype=np.uint8)\n",
    "    upper_skin = np.array([255, 180, 135], dtype=np.uint8)\n",
    "\n",
    "    # Extract skin color from image\n",
    "    mask1 = cv.inRange(img_ycrcb1, lower_skin, upper_skin)\n",
    "    mask2 = cv.inRange(img_ycrcb2, lower_skin, upper_skin)\n",
    "\n",
    "    # Apply morphological operations to remove noise from mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    mask1 = cv.erode(mask1, kernel, iterations=1)\n",
    "    mask1 = cv.dilate(mask1, kernel, iterations=1)\n",
    "\n",
    "    mask2 = cv.erode(mask2, kernel, iterations=1)\n",
    "    mask2 = cv.dilate(mask2, kernel, iterations=1)\n",
    "\n",
    "    # Apply mask to original image to extract hand\n",
    "    # result1 = cv.bitwise_and(img, img, mask=mask1)\n",
    "    # result2 = cv.bitwise_and(img, img, mask=mask2)\n",
    "    result11 = cv.bitwise_and(img, img, mask=mask1)\n",
    "    result22 = cv.bitwise_and(img, img, mask=mask2)\n",
    "\n",
    "    mean1 = np.mean(result11)\n",
    "    mean2 = np.mean(result22)\n",
    "    # print(mean1, mean2)\n",
    "    if mean1 > mean2:\n",
    "        result = result1\n",
    "    else:\n",
    "        result = result2\n",
    "    # Reshape the image to a 2D array of pixels and 3 color values (RGB)\n",
    "    rows, cols = result.shape[0], result.shape[1]\n",
    "    image_2d = result.reshape(rows*cols, 3)\n",
    "\n",
    "    # Perform k-means clustering with 3 clusters using OpenCV\n",
    "    criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    flags = cv.KMEANS_RANDOM_CENTERS\n",
    "    compactness, labels, centers = cv.kmeans(image_2d.astype(np.float32), 2, None, criteria, 10, flags)\n",
    "\n",
    "    # Reshape the labels back into the original image shape\n",
    "    labels_2d = labels.reshape(rows, cols)\n",
    "\n",
    "    # Get the pixel indices for each label\n",
    "    indices_0 = (labels_2d == 0)\n",
    "    indices_1 = (labels_2d == 1)\n",
    "    # indices_2 = (labels_2d == 2)\n",
    "    # Get a separate image for each cluster\n",
    "    result_0 = result.copy()\n",
    "    result_0[~indices_0] = 0\n",
    "\n",
    "    result_1 = result.copy()\n",
    "    result_1[~indices_1] = 0\n",
    "\n",
    "    # result_2 = result.copy()\n",
    "    # result_2[~indices_2] = 0\n",
    "    # io.imshow(result_0)\n",
    "    # io.show()\n",
    "    # io.imshow(result_1)\n",
    "    # io.show()\n",
    "\n",
    "    mean_0 = np.mean(result_0)\n",
    "    mean_1 = np.mean(result_1)\n",
    "    print(mean_0, mean_1)\n",
    "    if mean_1 > mean_0:\n",
    "        result_temp = result_1\n",
    "        indices_temp = indices_1\n",
    "    else:\n",
    "        result_temp = result_0\n",
    "        indices_temp = indices_0\n",
    "    #  Create a mask for the hand using the pixel indices of one of the clusters\n",
    "    # mask = np.zeros((rows, cols), dtype=bool)\n",
    "    # mask[indices_temp] = True\n",
    "\n",
    "    # # Apply the mask to the original image to get only the hand\n",
    "    # hand_image = np.zeros_like(result)\n",
    "    # hand_image[mask] = result[mask]\n",
    "    end_time = time.time()\n",
    "    takenTime = end_time - start_time\n",
    "    # io.imshow(hand_image)\n",
    "    # io.show()\n",
    "    cv.imshow('result_temp',  cv.resize(result_temp, (1024, 512)))\n",
    "    # cv.waitKey(0)\n",
    "    # cv.imshow('hand_image',  cv.resize(hand_image, (1024, 512)))\n",
    "    # cv.waitKey(0)\n",
    "    \n",
    "    #print taken time in percsion of 2\n",
    "    print(\"Time taken: {:.2f} seconds\".format(takenTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9951824  0.02116471 0.03659732 0.02557403 0.03174707 0.00573211\n",
      " 0.02910148 0.02072378 0.06966718]\n",
      "0.9951824\n",
      "[0.952756   0.15735564 0.16166674 0.10885561 0.0991556  0.03556668\n",
      " 0.05496669 0.07867782 0.09592227]\n",
      "0.952756\n",
      "[0.9586233  0.11969666 0.16589537 0.10499708 0.09974722 0.03569901\n",
      " 0.06614815 0.07874781 0.07979777]\n",
      "0.9586233\n",
      "[0.95942575 0.14144677 0.14254326 0.10197325 0.08662244 0.03399108\n",
      " 0.08004352 0.08114    0.08442947]\n",
      "0.95942575\n",
      "[0.96215767 0.10727891 0.13633361 0.09386905 0.09722151 0.02570224\n",
      " 0.06928429 0.09051657 0.11063137]\n",
      "0.96215767\n",
      "[0.9547946  0.15227807 0.15672414 0.1067058  0.08780998 0.02889949\n",
      " 0.06446809 0.07002567 0.10781731]\n",
      "0.9547946\n",
      "[0.9480657  0.1404112  0.16129881 0.11140062 0.08819216 0.02320846\n",
      " 0.09631512 0.09863597 0.1253257 ]\n",
      "0.9480657\n",
      "[0.94734025 0.1464682  0.14378072 0.12496829 0.09809339 0.02015617\n",
      " 0.08734342 0.10078087 0.13034327]\n",
      "0.94734025\n",
      "[0.956868   0.18914832 0.12556906 0.07152668 0.06516875 0.02384223\n",
      " 0.03973704 0.07470564 0.12556906]\n",
      "0.956868\n",
      "[0.96984404 0.12604472 0.12954596 0.08227919 0.06302236 0.02275807\n",
      " 0.04901739 0.04901739 0.10328664]\n",
      "0.96984404\n"
     ]
    }
   ],
   "source": [
    "time_taken = 0\n",
    "img_width = 120\n",
    "for i in range(1,11):\n",
    "    # Load the image\n",
    "    img = cv.imread(f\"../Dataset_0-5/men/0/0_men ({i}).JPG\")\n",
    "    h, w = img.shape[:2]\n",
    "    new_height = int(h * img_width / w)\n",
    "    img_size = (img_width, new_height)\n",
    "    img = cv.resize(img, img_size)    # resize image\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    # Compute the 58ULBP code for the grayscale image\n",
    "    code = Utils.get_9ULBP(gray)\n",
    "    # print(type(code))\n",
    "\n",
    "    print(code)\n",
    "    print(code.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = cv.imread('../Dataset_0-5/men/2/2_men (9).JPG')\n",
    "\n",
    "# Convert image to YCrCb color space\n",
    "img_ycrcb = cv.cvtColor(img, cv.COLOR_BGR2YCrCb)\n",
    "\n",
    "# Define range of skin color in YCrCb color space\n",
    "lower_skin = np.array([0, 135, 85], dtype=np.uint8)\n",
    "upper_skin = np.array([255, 180, 135], dtype=np.uint8)\n",
    "\n",
    "# Extract skin color from image\n",
    "mask = cv.inRange(img_ycrcb, lower_skin, upper_skin)\n",
    "\n",
    "# Apply morphological operations to remove noise from mask\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "mask = cv.erode(mask, kernel, iterations=1)\n",
    "mask = cv.dilate(mask, kernel, iterations=1)\n",
    "\n",
    "# Apply mask to original image to extract hand\n",
    "result = cv.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv.imshow('r',  cv.resize(result, (1024, 512)))\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05295024 0.15348765 0.2945944  ... 0.02164842 0.00704529 0.01718291]\n",
      "0.9041685\n",
      "************************************************\n",
      "[0.36488992 0.2491917  0.09057675 ... 0.14185953 0.08116683 0.0228403 ]\n",
      "0.5263316\n",
      "************************************************\n",
      "[0.30413458 0.30413458 0.04647462 ... 0.1307406  0.23544417 0.20929918]\n",
      "0.529315\n",
      "************************************************\n",
      "[0.2040595  0.20958178 0.19479568 ... 0.08541711 0.048785   0.01790663]\n",
      "0.4478565\n",
      "************************************************\n",
      "[0.2928592  0.2928592  0.22016443 ... 0.07346305 0.03220836 0.04575601]\n",
      "0.55554265\n",
      "************************************************\n",
      "[0.1525748  0.23331986 0.20184182 ... 0.12034313 0.19865091 0.19646692]\n",
      "0.52508473\n",
      "************************************************\n",
      "[0.24181023 0.24181023 0.24181023 ... 0.05440654 0.00614775 0.0028718 ]\n",
      "0.48858282\n",
      "************************************************\n",
      "[0.2566191  0.1638082  0.074618   ... 0.18375733 0.05513272 0.00688975]\n",
      "0.452667\n",
      "************************************************\n",
      "[0.22912736 0.12253898 0.01676359 ... 0.00120583 0.15209542 0.36708075]\n",
      "0.48380098\n",
      "************************************************\n",
      "[0.2586885  0.15310149 0.0944564  ... 0.         0.         0.        ]\n",
      "0.4940066\n",
      "************************************************\n"
     ]
    }
   ],
   "source": [
    "# Set HOG parameters\n",
    "win_size = (64, 64)\n",
    "block_size = (16, 16)\n",
    "block_stride = (8, 8)\n",
    "cell_size = (8, 8)\n",
    "nbins = 9\n",
    "# Create HOG descriptor\n",
    "hog = cv.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "for i in range(1,11):\n",
    "    # Load the image\n",
    "    img = cv.imread(f\"../Dataset_0-5/men/0/0_men ({i}).JPG\")\n",
    "    img_width = 120\n",
    "    h, w = img.shape[:2]\n",
    "    new_height = int(h * img_width / w)\n",
    "    img_size = (img_width, new_height)\n",
    "    img = cv.resize(img, img_size)    # resize image\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    f = hog.compute(gray)\n",
    "    print(f)\n",
    "    print(f.max())\n",
    "    print(\"************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
